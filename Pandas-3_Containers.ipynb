{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Pandas logo](img/pandas.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Containers\n",
    "\n",
    "Let us backup a little to understand what Pandas containers really are.  We have primarily given examples of DataFrames in earlier modules, and indeed that is the primary object you will work with.  Moreover, we loosely implied a Pandas DataFrame was a wrapper around a 2-D NumPy array; that is not a bad starting metaphor, but it is slightly wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.training import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "The basic data container in Pandas is actually a *Series*, not a DataFrame.  A `pd.Series` indeed wraps a NumPy array, but always a 1-D array.  The principle addition a Pandas Series gives us is labels on its rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.arange(10, 15)\n",
    "arr2 = np.arange(1., 6)\n",
    "arr3 = np.array(['foo', 'bar', 'baz', 'bam', 'fiz'])\n",
    "s1, s2, s3 = (pd.Series(arr) for arr in (arr1, arr2, arr3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('arr1')\n",
    "print(arr1)\n",
    "print('s1')\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the most part, working with a Series or an array are similar with default indices (as we have used so far here). The screen display is a little bit different, but accessing items by index is the same. Indeed, most code that expects to work with 1-D NumPy arrays will seamlessly handle Pandas Series also.  You often do not need to think about the difference when writing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice\n",
    "print('dtype:', arr1.dtype)\n",
    "arr1[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice\n",
    "s1[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where things are more evidently different is when the index is something different from successive integers starting at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_new = pd.Series(arr1, index=arr3)\n",
    "s_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can access rows by meaningful names\n",
    "s_new[['foo', 'bam']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But can still use \"accessor\" to access by position\n",
    "s_new.iloc[[0, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid ambiguity, best practice uses accessor for index too\n",
    "s_new.loc[['foo', 'bam']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "\n",
    "A DataFrame is **not** in fact a wrapper around a 2-D array, but more like a \"bag\" or \"mapping\" of column names to multiple Pandas Series.  An additional constraint (and capability) exists in DataFrames that all the Series contained in a DataFrame must use the same index.  This is a powerful abstraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to understand why DataFrames must be \"bags\" of 1-D structures is to think about the fact that they often contain different datatypes per column.  In contrast, N-dimensional arrays *always* have a homogeneous datatype across all values inside them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Words': s3, 'Integers': s1, 'Floats': s2})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can absolutely work with these sequential integers as index.  But notice that the index is \"sticky\" in a way it is not for a 2-D NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After operations, index might not be sequential integers\n",
    "df2 = df.loc[[0, 3]].copy()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is an index called '3'\n",
    "df2.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But there is no index called '1'\n",
    "try:\n",
    "    print(df2.loc[1])\n",
    "except Exception as err:\n",
    "    print(err.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2d = np.c_[arr1, arr2]\n",
    "arr2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2d_2 = arr2d[[0, 3]]\n",
    "arr2d_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In contrast to DataFrame, array is always sequentially indexed\n",
    "arr2d_2[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames may be created in numerous ways, both from input data files and with different patterns in the class initialization.  Many variants of these are left to the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "Let us use one particular column as our index for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = df.set_index('Words')\n",
    "df_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names.loc[['foo', 'bam']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use more general patterns to get at portions of the data by combining predicates (about rows) with column selectors.  As with NumPy, commas separate \"dimensions.\" The index may be drawn from the `RangeIndex` that is applied by default, but the row labels will still remain after the selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = pd.read_csv('data/wisconsin.csv')                     \n",
    "focus = cancer.loc[cancer['mean radius'] > 24, 'mean radius':'mean area']\n",
    "focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``RangeIndex`` is an efficient & lazy way to represent a sequence.\n",
    "\n",
    "Other common **Index** types are\n",
    "\n",
    "|    Class      |         Type of Values     |\n",
    "|---------------|----------------------------|\n",
    "|`Index`        | Anything, often strings    |\n",
    "|`Int64Index`   | 64-bit integers            |\n",
    "|`DatetimeIndex`| `TimeStamp` objects        |\n",
    "|`RangeIndex`   | `range()`-like integers    |\n",
    "|`MultiIndex`   | Hierarchical values        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also choose an index by indicating it in the initializer, rather than by later calling `.set_index()` on the DataFrame.  Notice the crucial differences in this constructor:\n",
    "\n",
    "* The columns are indicated with the keyword argument `data` and a dictionary\n",
    "* The index is indicated with the keyword argument `index`\n",
    "* We cannot use the Series that already have different row labels (index)\n",
    "  * Can use original NumPy array for values\n",
    "  * Can use series.array for unlabelled value\n",
    "  * Can cast back to NumPy with `np.array(series)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data={'Integers': arr1, 'Floats': s2.array}, index=s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resetting index\n",
    "\n",
    "We can always remove the index from a DataFrame, which will move the values back to a regular column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names.loc[['foo', 'bam']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column 'index' is probably pointless, but this follows from rule\n",
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "The exercises below can each be done with a provided Python object.  These objects have a few properties.  Simply echoing the object in a cell produces a \"pretty\" display that may emphasize some aspect of the data of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each object has an `obj.data` attribute contains some sort of source data you should work with.  Each also contains an `obj.result` attribute that contains a some sort of transformation of the original data which you are trying to match.  In some cases, an exercise may have additional special attributes or methods that will be discussed in the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from src.pandas_exercises import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Pandas DataFrames may be read from Python dictionaries of several different styles.  Try to replicate that transformation.  The *original* DataFrame is the familiar `patients` one. Some of these round-trips are lossy?  \n",
    "\n",
    "Hint: you probably want to utilize the help system built into Jupyter to explore some details not shown in examples.  E.g. run `pd.DataFrame?` in a cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Extra credit*: Think about how you might address the lossiness, where it is an issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex3_1.ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row oriented\n",
    "pprint(ex3_1.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the dictionary\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record oriented\n",
    "pprint(ex3_2.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the dictionary\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column oriented\n",
    "pprint(ex3_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the dictionary\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Using the same `patients` DateFrame we have used for a number of examples, set its index to an upper case version of the patient name, but retain the mixed case version as an additional column.  Since many names in various languages use varying capitalization rules, the transformation to upper case is a lossy operation and we do not want to discard information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* While you are free to discover a more Pandas-native way of solving this, the standard Python `str.upper()` method is enough to arrive at an answer.  However, do not solve the problem purely manually (e.g. by simply typing the four names in upper case; pretend the DataFrame had thousands of records rather than just four)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex3_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data into result\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Create a DataFrame based on a 2-D NumPy array (here of random values).  We want to name the rows with labels 'Alice', 'Bob', 'Carlos', 'Dan', and the columns with labels 'key1', 'key2', 'key3', 'key4'.  These choices are reminiscent of names often used in cryptography, but these specific values have no special connection to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex3_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame based on data and matching result\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having solved the problem one way, see if you can play around with Pandas methods for constructing DataFrames to create an equal DataFrame using different APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from data, matching result (2nd approach)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Based on a Series containing platform-native integer values, construct a DataFrame with columns named 'Int16', 'Float32', 'Complex', and 'String'.  The values inside each column should be \"the same\" as those in the Series, but their types should correspond to the column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Extra credit:* Also set the index of the DataFrame you build be the value in their original datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex3_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ex3_6.result.dtypes)\n",
    "print(ex3_6.result.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame based on Series data, with columns described\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
